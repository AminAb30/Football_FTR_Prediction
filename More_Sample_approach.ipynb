{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Prediction Of Final Result Of Football Matches Based on Half Time Statistics\n",
        "\n",
        "### Dataset Structure\n",
        "The dataset contains the following columns:\n",
        "\n",
        "- Div: League identifier (F1=French Ligue 1, I1=Italian Serie A, SP1=Spanish La Liga)\n",
        "\n",
        "- HomeTeam: Home team name\n",
        "\n",
        "- AwayTeam: Away team name\n",
        "\n",
        "- FTR: Full-time result (H=Home win, D=Draw, A=Away win)\n",
        "\n",
        "- HTHG: Home team half-time goals\n",
        "\n",
        "- HTAG: Away team half-time goals\n",
        "\n",
        "- HTR: Half-time result (H=Home lead, D=Draw, A=Away lead)\n",
        "\n",
        "- BWD: Betting odds for draw\n",
        "\n",
        "- BWA: Betting odds for away win\n",
        "\n",
        "- BWH: Betting odds for home win\n",
        "\n",
        "- Year: Match year\n",
        "\n",
        "- Month: Match month\n",
        "\n",
        "- Day: Match day\n",
        "\n",
        "#### What we have in this dataset?\n",
        "- Coverage: The dataset includes matches from:\n",
        "\n",
        "French Ligue 1 (2019-2022)\n",
        "\n",
        "Italian Serie A (2021-2022 seasons)\n",
        "\n",
        "Spanish La Liga (2021-2022 seasons)\n",
        "\n",
        "- Betting Data: The dataset contains betting odds (BWH, BWD, BWA) which could be valuable for predictive modeling.\n",
        "\n",
        "- Temporal Data: Each match has a complete date (year, month, day) allowing for temporal analysis.\n",
        "\n",
        "- Match Phases: Contains both half-time and full-time results, enabling analysis of how matches develop.\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install necessary libraries"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "id": "8C1jZAKs8Eqc",
        "gather": {
          "logged": 1745894719990
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing Data"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#start by importing merged dataset\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "df = pd.read_csv('merged_df_File.csv')\n",
        "print(df.head(5))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "   FTAG  WHD    HS   AY   WHH    AwayTeam   HR        Date HTR  HTAG  ...  \\\n0     3  3.5   7.0  2.0  2.80        Lyon  1.0  09/08/2019   A   2.0  ...   \n1     2  3.6  10.0  0.0  1.63       Reims  0.0  10/08/2019   D   0.0  ...   \n2     1  3.1  14.0  1.0  2.35    Bordeaux  0.0  10/08/2019   H   1.0  ...   \n3     1  3.3  16.0  0.0  2.30    Toulouse  0.0  10/08/2019   H   0.0  ...   \n4     2  3.3  15.0  2.0  3.60  St Etienne  0.0  10/08/2019   A   2.0  ...   \n\n    AR   HomeTeam  WHA   HY   BWD  FTHG  FTR    AS   BWA  HTHG  \n0  0.0     Monaco  2.4  2.0  3.30     0    A  13.0  2.40   0.0  \n1  0.0  Marseille  5.8  1.0  3.60     0    A   8.0  5.75   0.0  \n2  0.0     Angers  3.2  2.0  3.10     3    H   8.0  3.10   3.0  \n3  0.0      Brest  3.1  0.0  3.10     1    D  13.0  3.00   1.0  \n4  0.0      Dijon  2.1  0.0  3.25     1    A  12.0  2.05   1.0  \n\n[5 rows x 22 columns]\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "D20VMyQo7u6k",
        "outputId": "74b69bb9-ec86-4bf5-e2f2-55f5c03702f1",
        "gather": {
          "logged": 1745894722263
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  Define the columns to keep (excluding duplicates like HG, AG, Res)\n",
        "columns_to_keep = [\n",
        "    'Div', 'Date', 'HomeTeam', 'AwayTeam','FTR',\n",
        "    'HTHG', 'HTAG', 'HTR', 'BWD', 'BWA', 'BWH'\n",
        "]\n",
        "\n",
        "# Check which columns are actually present in the dataset\n",
        "available_columns = [col for col in columns_to_keep if col in df.columns]\n",
        "df = df[available_columns]\n"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "id": "6-u-Vxfcgabm",
        "gather": {
          "logged": 1745894726554
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# preprocessing"
      ],
      "metadata": {
        "id": "8_Kw9Q2l7t28"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Change Date Structure\n",
        "\n",
        "We decided to split the Date variable into smaller parts: Year, Month, and Day. However, the challenge is that there are three different formats of information in this column: dd/mm/yyyy, d/m/yyyy, and dd/mm/yy."
      ],
      "metadata": {
        "id": "sUuxd2CyaAh3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Preprocess the Date column to handle mixed formats and two-digit years\n",
        "def preprocess_date(date_str):\n",
        "    # Split the date string into day, month, year\n",
        "    parts = date_str.split('/')\n",
        "    day, month, year = parts[0], parts[1], parts[2]\n",
        "\n",
        "    # Pad day and month with leading zeros if needed (e.g., '5' -> '05')\n",
        "    day = day.zfill(2)\n",
        "    month = month.zfill(2)\n",
        "\n",
        "    # Handle two-digit years by prepending '20'\n",
        "    if len(year) == 2:\n",
        "        year = '20' + year\n",
        "\n",
        "    # Reconstruct the date string in dd/mm/yyyy format\n",
        "    return f\"{day}/{month}/{year}\"\n",
        "\n",
        "# Apply the preprocessing to the Date column\n",
        "df['Date'] = df['Date'].apply(preprocess_date)\n",
        "\n",
        "# Step 2: Convert the normalized Date column to datetime\n",
        "df['Date'] = pd.to_datetime(df['Date'], format='%d/%m/%Y', errors='coerce')\n",
        "\n",
        "# Step 3: Extract Year, Month, and Day into new columns\n",
        "df['Year'] = df['Date'].dt.year\n",
        "df['Month'] = df['Date'].dt.month\n",
        "df['Day'] = df['Date'].dt.day\n",
        "\n",
        "# Step 4: Drop the original Date column (optional, comment out if you want to keep it)\n",
        "df = df.drop('Date', axis=1)\n",
        "\n",
        "# Step 5: Verify the new columns\n",
        "print(\"First 5 rows with new Year, Month, Day columns:\")\n",
        "print(df[['Year', 'Month', 'Day']].head())\n",
        "\n",
        "# Check for nulls in the new columns (should be none since Date has no nulls)\n",
        "print(\"\\nNull values in new date columns:\")\n",
        "print(df[['Year', 'Month', 'Day']].isnull().sum())\n",
        "\n",
        "# Step 6: Save the updated dataset\n",
        "#df.to_csv('football_data_with_date_split_corrected.csv', index=False)\n",
        "#print(\"Dataset with correctly split date columns saved to 'football_data_with_date_split_corrected.csv'\")\n",
        "\n",
        "# Display the first few rows of the updated dataset\n",
        "print(\"\\nFirst 5 rows of the updated dataset:\")\n",
        "print(df.head())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "First 5 rows with new Year, Month, Day columns:\n   Year  Month  Day\n0  2019      8    9\n1  2019      8   10\n2  2019      8   10\n3  2019      8   10\n4  2019      8   10\n\nNull values in new date columns:\nYear     0\nMonth    0\nDay      0\ndtype: int64\nDataset with correctly split date columns saved to 'football_data_with_date_split_corrected.csv'\n\nFirst 5 rows of the updated dataset:\n  Div   HomeTeam    AwayTeam FTR  HTHG  HTAG HTR   BWD   BWA   BWH  Year  \\\n0  F1     Monaco        Lyon   A   0.0   2.0   A  3.30  2.40  2.85  2019   \n1  F1  Marseille       Reims   A   0.0   0.0   D  3.60  5.75  1.62  2019   \n2  F1     Angers    Bordeaux   H   3.0   1.0   H  3.10  3.10  2.35  2019   \n3  F1      Brest    Toulouse   D   1.0   0.0   H  3.10  3.00  2.40  2019   \n4  F1      Dijon  St Etienne   A   1.0   2.0   A  3.25  2.05  3.60  2019   \n\n   Month  Day  \n0      8    9  \n1      8   10  \n2      8   10  \n3      8   10  \n4      8   10  \n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOBVCFNhaGCf",
        "outputId": "8da9c499-2d81-4960-fa24-796f61172cae",
        "gather": {
          "logged": 1745894736762
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Handling null values"
      ],
      "metadata": {
        "id": "WkCkkq1DAXJr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Verifying no null values remain\n",
        "print(\"Missing Values After Preprocessing:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Saving the preprocessed dataset to a new CSV file\n",
        "#df.to_csv('preprocessed_football_data.csv', index=False)\n",
        "#print(\"Preprocessed data saved to 'preprocessed_football_data.csv'\")\n",
        "\n",
        "# Displaying the first few rows of the preprocessed dataset\n",
        "print(\"\\nFirst 5 rows of preprocessed dataset:\")\n",
        "print(df.head())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Missing Values After Preprocessing:\nDiv           0\nHomeTeam      0\nAwayTeam      0\nFTR           0\nHTHG          4\nHTAG          4\nHTR           4\nBWD         645\nBWA         645\nBWH         645\nYear          0\nMonth         0\nDay           0\ndtype: int64\n\nFirst 5 rows of preprocessed dataset:\n  Div   HomeTeam    AwayTeam FTR  HTHG  HTAG HTR   BWD   BWA   BWH  Year  \\\n0  F1     Monaco        Lyon   A   0.0   2.0   A  3.30  2.40  2.85  2019   \n1  F1  Marseille       Reims   A   0.0   0.0   D  3.60  5.75  1.62  2019   \n2  F1     Angers    Bordeaux   H   3.0   1.0   H  3.10  3.10  2.35  2019   \n3  F1      Brest    Toulouse   D   1.0   0.0   H  3.10  3.00  2.40  2019   \n4  F1      Dijon  St Etienne   A   1.0   2.0   A  3.25  2.05  3.60  2019   \n\n   Month  Day  \n0      8    9  \n1      8   10  \n2      8   10  \n3      8   10  \n4      8   10  \n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BHCY_wRaqMv",
        "outputId": "5a51f480-e5c1-4ba7-fc8b-2b1ba9d5f9f5",
        "gather": {
          "logged": 1745894752847
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The null values are in BWS, BWA and BWH columns that shows the odd values for wining Home team, Away team of draw. for handling the null values for those variable I decided to fill in these missing odds with a number that is neutral, fair, and doesn't bias your future analysis — like replacing with 50% probability when there are two outcomes. Here, because football matches have three outcomes, I want something equivalent for three possibilities.\n",
        "In decimal odds:\n",
        "\n",
        "- Probability = 1 / Decimal Odds\n",
        "\n",
        "- So fair odds are the reciprocal of probability.\n",
        "\n",
        "If you assume that each outcome (home win, draw, away win) is equally likely (purely 33.33% chance each).\n",
        "This means each event is equally likely (one-third chance), which is the most neutral assumption when you have 3 possible outcomes and no other information.\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling null values as specified\n",
        "# Step 1: Replace null values in betting odds columns with 1\n",
        "betting_columns = ['BWD', 'BWA', 'BWH']\n",
        "for col in betting_columns:\n",
        "    df[col] = df[col].fillna(3)\n",
        "\n",
        "# Step 2: Drop rows where HTR has null values\n",
        "df = df.dropna(subset=['HTR', 'HTHG', 'HTAG' ])\n",
        "\n",
        "\n",
        "# Step 4: Drop rows with null values in categorical columns\n",
        "categorical_columns = ['HomeTeam', 'AwayTeam', 'FTR', 'Div', 'Year', 'Month', 'Day']\n",
        "df = df.dropna(subset=categorical_columns)\n",
        "\n",
        "# Verifying no null values remain\n",
        "print(\"Missing Values After Preprocessing:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Saving the preprocessed dataset to a new CSV file\n",
        "df.to_csv('preprocessed_football_data.csv', index=False)\n",
        "print(\"Preprocessed data saved to 'preprocessed_football_data.csv'\")\n",
        "\n",
        "# Displaying the first few rows of the preprocessed dataset\n",
        "print(\"\\nFirst 5 rows of preprocessed dataset:\")\n",
        "print(df.head())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Missing Values After Preprocessing:\nDiv         0\nHomeTeam    0\nAwayTeam    0\nFTR         0\nHTHG        0\nHTAG        0\nHTR         0\nBWD         0\nBWA         0\nBWH         0\nYear        0\nMonth       0\nDay         0\ndtype: int64\nPreprocessed data saved to 'preprocessed_football_data.csv'\n\nFirst 5 rows of preprocessed dataset:\n  Div   HomeTeam    AwayTeam FTR  HTHG  HTAG HTR   BWD   BWA   BWH  Year  \\\n0  F1     Monaco        Lyon   A   0.0   2.0   A  3.30  2.40  2.85  2019   \n1  F1  Marseille       Reims   A   0.0   0.0   D  3.60  5.75  1.62  2019   \n2  F1     Angers    Bordeaux   H   3.0   1.0   H  3.10  3.10  2.35  2019   \n3  F1      Brest    Toulouse   D   1.0   0.0   H  3.10  3.00  2.40  2019   \n4  F1      Dijon  St Etienne   A   1.0   2.0   A  3.25  2.05  3.60  2019   \n\n   Month  Day  \n0      8    9  \n1      8   10  \n2      8   10  \n3      8   10  \n4      8   10  \n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Xnhp2Yb7qKa",
        "outputId": "459210ea-8a41-4841-a369-6f91c6def0a9",
        "gather": {
          "logged": 1745894758040
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the updated DataFrame to a new CSV\n",
        "#df.to_csv('updated_football_date_seperated.csv', index=False)"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "id": "YWbCuFMYNJnx",
        "gather": {
          "logged": 1745864828036
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Engineering\n",
        "\n",
        "## Last game result (win/draw/loss) for both home and away teams"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "In this part I'll adds feature engineering columns to track each team's recent form (win/draw/loss) for both home and away teams"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "#df = pd.read_csv('preprocessed_football_data.csv')\n",
        "\n",
        "# Sort by date to ensure chronological order\n",
        "df['Date'] = pd.to_datetime(df[['Year', 'Month', 'Day']])\n",
        "df = df.sort_values(['Div', 'Date']).reset_index(drop=True)\n",
        "\n",
        "# Initialize new columns\n",
        "for prefix in ['Home', 'Away']:\n",
        "    df[f'{prefix}_PrevWin'] = 0\n",
        "    df[f'{prefix}_PrevDraw'] = 0\n",
        "    df[f'{prefix}_PrevLoss'] = 0\n",
        "\n",
        "# Create a dictionary to track each team's last result\n",
        "team_last_result = {}"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1745894775541
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's create a larger sample to see the form columns working\n",
        "#sample_size = 50  # Look at first 50 matches\n",
        "#sample_df = df.head(sample_size).copy()\n",
        "\n",
        "sample_df = df\n",
        "\n",
        "# Re-run the form calculation just on this sample\n",
        "team_last_result = {}\n",
        "for idx, row in sample_df.iterrows():\n",
        "    home_team = row['HomeTeam']\n",
        "    away_team = row['AwayTeam']\n",
        "    \n",
        "    # Get home team's last result\n",
        "    if home_team in team_last_result:\n",
        "        last_result = team_last_result[home_team]\n",
        "        sample_df.at[idx, 'Home_PrevWin'] = 1 if last_result == 'W' else 0\n",
        "        sample_df.at[idx, 'Home_PrevDraw'] = 1 if last_result == 'D' else 0\n",
        "        sample_df.at[idx, 'Home_PrevLoss'] = 1 if last_result == 'L' else 0\n",
        "    \n",
        "    # Get away team's last result\n",
        "    if away_team in team_last_result:\n",
        "        last_result = team_last_result[away_team]\n",
        "        sample_df.at[idx, 'Away_PrevWin'] = 1 if last_result == 'W' else 0\n",
        "        sample_df.at[idx, 'Away_PrevDraw'] = 1 if last_result == 'D' else 0\n",
        "        sample_df.at[idx, 'Away_PrevLoss'] = 1 if last_result == 'L' else 0\n",
        "    \n",
        "    # Update team results with current match\n",
        "    if row['FTR'] == 'H':\n",
        "        team_last_result[home_team] = 'W'\n",
        "        team_last_result[away_team] = 'L'\n",
        "    elif row['FTR'] == 'A':\n",
        "        team_last_result[home_team] = 'L'\n",
        "        team_last_result[away_team] = 'W'\n",
        "    else:  # Draw\n",
        "        team_last_result[home_team] = 'D'\n",
        "        team_last_result[away_team] = 'D'\n",
        "\n",
        "# Show matches where at least one form indicator is 1\n",
        "has_history = df[(sample_df['Home_PrevWin'] == 1) | \n",
        "                        (sample_df['Home_PrevDraw'] == 1) | \n",
        "                        (sample_df['Home_PrevLoss'] == 1) |\n",
        "                        (sample_df['Away_PrevWin'] == 1) | \n",
        "                        (sample_df['Away_PrevDraw'] == 1) | \n",
        "                        (sample_df['Away_PrevLoss'] == 1)]\n",
        "\n",
        "print(has_history[['Date', 'HomeTeam', 'AwayTeam', 'FTR', \n",
        "                   'Home_PrevWin', 'Home_PrevDraw', 'Home_PrevLoss',\n",
        "                   'Away_PrevWin', 'Away_PrevDraw', 'Away_PrevLoss']])\n",
        "df = has_history                   "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "            Date        HomeTeam       AwayTeam FTR  Home_PrevWin  \\\n9     2005-08-13       Bielefeld        Hamburg   A             0   \n10    2005-08-13        Dortmund     Schalke 04   A             0   \n11    2005-08-13          Hertha  Ein Frankfurt   H             0   \n12    2005-08-13  Kaiserslautern       Duisburg   H             0   \n13    2005-08-13      Leverkusen  Bayern Munich   A             1   \n...          ...             ...            ...  ..           ...   \n70029 2025-03-16         Leganes          Betis   A             0   \n70030 2025-03-16         Sevilla     Ath Bilbao   A             0   \n70031 2025-03-16         Osasuna         Getafe   A             0   \n70032 2025-03-16       Vallecano       Sociedad   D             0   \n70033 2025-03-16      Ath Madrid      Barcelona   A             0   \n\n       Home_PrevDraw  Home_PrevLoss  Away_PrevWin  Away_PrevDraw  \\\n9                  0              1             1              0   \n10                 1              0             1              0   \n11                 1              0             0              0   \n12                 0              1             0              1   \n13                 0              0             1              0   \n...              ...            ...           ...            ...   \n70029              0              1             1              0   \n70030              0              1             1              0   \n70031              0              1             1              0   \n70032              1              0             0              1   \n70033              0              1             1              0   \n\n       Away_PrevLoss  \n9                  0  \n10                 0  \n11                 1  \n12                 0  \n13                 0  \n...              ...  \n70029              0  \n70030              0  \n70031              0  \n70032              0  \n70033              0  \n\n[69983 rows x 10 columns]\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1745894786292
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Key approaches and technics that i used in this part is:\n",
        "- Instead of complex merging operations, this uses a dictionary to track each team's last result.\n",
        "- Sets the form columns directly during iteration, avoiding merge issues.\n",
        "-  Handles cases where teams haven't played before (initializes with 0).\n",
        "- Ensures chronological processing of matches.\n",
        "\n",
        "\n",
        "The new columns will show:\n",
        "For each team in each match:\n",
        "\n",
        "**Home_PrevWin:** 1 if home team won their last match, 0 otherwise\n",
        "\n",
        "**Home_PrevDraw:** 1 if home team drew their last match, 0 otherwise\n",
        "\n",
        "**Home_PrevLoss:** 1 if home team lost their last match, 0 otherwise\n",
        "\n",
        "(Same for Away team columns)\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving the preprocessed dataset to a new CSV file\n",
        "#df.to_csv('Step5_football_data_with_PrevMatch_result.csv', index=False)\n",
        "#print(\"feature eng data saved to 'Step5_football_data_with_PrevMatch_result.csv'\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "feature eng data saved to 'Step5_football_data_with_PrevMatch_result.csv'\n"
        }
      ],
      "execution_count": 24,
      "metadata": {
        "gather": {
          "logged": 1745888727888
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extend to More Matches (N-Game Form)\n",
        "\n",
        "The target of this part is track form over the last 3 matches"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Track last 3 matches' form\n",
        "def get_last_n_results(team, date, n=3):\n",
        "    team_matches = df[((df['HomeTeam'] == team) | (df['AwayTeam'] == team)) & (df['Date'] < date)]\n",
        "    last_n = team_matches.sort_values('Date').tail(n)\n",
        "    \n",
        "    wins = 0\n",
        "    draws = 0\n",
        "    losses = 0\n",
        "    \n",
        "    for _, row in last_n.iterrows():\n",
        "        if row['HomeTeam'] == team:\n",
        "            if row['FTR'] == 'H': wins += 1\n",
        "            elif row['FTR'] == 'D': draws += 1\n",
        "            else: losses += 1\n",
        "        else:\n",
        "            if row['FTR'] == 'A': wins += 1\n",
        "            elif row['FTR'] == 'D': draws += 1\n",
        "            else: losses += 1\n",
        "    \n",
        "    return wins, draws, losses\n",
        "\n",
        "# Apply to each match\n",
        "for idx, row in df.iterrows():\n",
        "    home_team = row['HomeTeam']\n",
        "    away_team = row['AwayTeam']\n",
        "    date = row['Date']\n",
        "    \n",
        "    # Home team's last 3 matches\n",
        "    h_wins, h_draws, h_losses = get_last_n_results(home_team, date, 3)\n",
        "    df.at[idx, 'Home_Last3Wins'] = h_wins\n",
        "    df.at[idx, 'Home_Last3Draws'] = h_draws\n",
        "    df.at[idx, 'Home_Last3Losses'] = h_losses\n",
        "    \n",
        "    # Away team's last 3 matches\n",
        "    a_wins, a_draws, a_losses = get_last_n_results(away_team, date, 3)\n",
        "    df.at[idx, 'Away_Last3Wins'] = a_wins\n",
        "    df.at[idx, 'Away_Last3Draws'] = a_draws\n",
        "    df.at[idx, 'Away_Last3Losses'] = a_losses"
      ],
      "outputs": [],
      "execution_count": 25,
      "metadata": {
        "gather": {
          "logged": 1745889806371
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(5)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 22,
          "data": {
            "text/plain": "   Div        HomeTeam       AwayTeam FTR  HTHG  HTAG HTR   BWD   BWA   BWH  \\\n9   D1       Bielefeld        Hamburg   A   0.0   0.0   D  3.40  2.05  3.15   \n10  D1        Dortmund     Schalke 04   A   1.0   1.0   D  3.25  2.65  2.40   \n11  D1          Hertha  Ein Frankfurt   H   0.0   0.0   D  4.50  7.20  1.35   \n12  D1  Kaiserslautern       Duisburg   H   2.0   1.0   H  3.50  4.40  1.70   \n13  D1      Leverkusen  Bayern Munich   A   1.0   3.0   A  3.40  2.10  3.00   \n\n    ...  Away_PrevLoss  Home_Last3Wins  Home_Last3Draws Home_Last3Losses  \\\n9   ...              0             0.0              0.0              0.0   \n10  ...              0             0.0              0.0              0.0   \n11  ...              1             0.0              0.0              0.0   \n12  ...              0             0.0              0.0              0.0   \n13  ...              0             0.0              0.0              0.0   \n\n    Away_Last3Wins  Away_Last3Draws  Away_Last3Losses  H2H_HomeWins  \\\n9              0.0              0.0               0.0             0   \n10             0.0              0.0               0.0             0   \n11             0.0              0.0               0.0             0   \n12             0.0              0.0               0.0             0   \n13             0.0              0.0               0.0             0   \n\n    H2H_Draws  H2H_AwayWins  \n9           0             0  \n10          0             0  \n11          0             0  \n12          0             0  \n13          0             0  \n\n[5 rows x 29 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Div</th>\n      <th>HomeTeam</th>\n      <th>AwayTeam</th>\n      <th>FTR</th>\n      <th>HTHG</th>\n      <th>HTAG</th>\n      <th>HTR</th>\n      <th>BWD</th>\n      <th>BWA</th>\n      <th>BWH</th>\n      <th>...</th>\n      <th>Away_PrevLoss</th>\n      <th>Home_Last3Wins</th>\n      <th>Home_Last3Draws</th>\n      <th>Home_Last3Losses</th>\n      <th>Away_Last3Wins</th>\n      <th>Away_Last3Draws</th>\n      <th>Away_Last3Losses</th>\n      <th>H2H_HomeWins</th>\n      <th>H2H_Draws</th>\n      <th>H2H_AwayWins</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>9</th>\n      <td>D1</td>\n      <td>Bielefeld</td>\n      <td>Hamburg</td>\n      <td>A</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>D</td>\n      <td>3.40</td>\n      <td>2.05</td>\n      <td>3.15</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>D1</td>\n      <td>Dortmund</td>\n      <td>Schalke 04</td>\n      <td>A</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>D</td>\n      <td>3.25</td>\n      <td>2.65</td>\n      <td>2.40</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>D1</td>\n      <td>Hertha</td>\n      <td>Ein Frankfurt</td>\n      <td>H</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>D</td>\n      <td>4.50</td>\n      <td>7.20</td>\n      <td>1.35</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>D1</td>\n      <td>Kaiserslautern</td>\n      <td>Duisburg</td>\n      <td>H</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>H</td>\n      <td>3.50</td>\n      <td>4.40</td>\n      <td>1.70</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>D1</td>\n      <td>Leverkusen</td>\n      <td>Bayern Munich</td>\n      <td>A</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>A</td>\n      <td>3.40</td>\n      <td>2.10</td>\n      <td>3.00</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 29 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 22,
      "metadata": {
        "gather": {
          "logged": 1745888334650
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Head-to-Head History\n",
        "the target of this part is check how teams performed against each other in the past (H2H_HomeWins)"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_h2h_form(home_team, away_team, date, n=3):\n",
        "    h2h_matches = df[((df['HomeTeam'] == home_team) & (df['AwayTeam'] == away_team)) | \n",
        "                     ((df['HomeTeam'] == away_team) & (df['AwayTeam'] == home_team))]\n",
        "    h2h_matches = h2h_matches[h2h_matches['Date'] < date].sort_values('Date').tail(n)\n",
        "    \n",
        "    home_wins = 0\n",
        "    draws = 0\n",
        "    away_wins = 0\n",
        "    \n",
        "    for _, row in h2h_matches.iterrows():\n",
        "        if row['FTR'] == 'H':\n",
        "            if row['HomeTeam'] == home_team: home_wins += 1\n",
        "            else: away_wins += 1\n",
        "        elif row['FTR'] == 'D':\n",
        "            draws += 1\n",
        "    \n",
        "    return home_wins, draws, away_wins\n",
        "\n",
        "# Apply to each match\n",
        "df[['H2H_HomeWins', 'H2H_Draws', 'H2H_AwayWins']] = df.apply(\n",
        "    lambda x: pd.Series(get_h2h_form(x['HomeTeam'], x['AwayTeam'], x['Date'], 3)),\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# Saving the preprocessed dataset to a new CSV file\n",
        "df.to_csv('Step7_football_data_with_HeadToHead_Histort.csv', index=False)\n",
        "print(\"feature eng data saved to 'Step7_football_data_with_HeadToHead_Histort.csv'\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/tmp/ipykernel_4431/1778122225.py:20: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df[['H2H_HomeWins', 'H2H_Draws', 'H2H_AwayWins']] = df.apply(\n/tmp/ipykernel_4431/1778122225.py:20: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df[['H2H_HomeWins', 'H2H_Draws', 'H2H_AwayWins']] = df.apply(\n/tmp/ipykernel_4431/1778122225.py:20: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df[['H2H_HomeWins', 'H2H_Draws', 'H2H_AwayWins']] = df.apply(\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "feature eng data saved to 'Step7_football_data_with_HeadToHead_Histort.csv'\n"
        }
      ],
      "execution_count": 21,
      "metadata": {
        "gather": {
          "logged": 1745888230131
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving the preprocessed dataset to a new CSV file\n",
        "#df.to_csv('sample ver.csv', index=False)\n"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1745894863630
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Models"
      ],
      "metadata": {
        "id": "FtyQR_oHUmGQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Preparation"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "\n",
        "# Load the data\n",
        "#df = pd.read_csv('sample ver.csv')\n",
        "\n",
        "# Convert 'Date' to datetime\n",
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "\n",
        "# Encode categorical features\n",
        "le_team = LabelEncoder()\n",
        "df['HomeTeam'] = le_team.fit_transform(df['HomeTeam'])\n",
        "df['AwayTeam'] = le_team.transform(df['AwayTeam'])  # Use same encoder\n",
        "\n",
        "le_ftr = LabelEncoder()\n",
        "df['FTR_encoded'] = le_ftr.fit_transform(df['FTR'])\n",
        "\n",
        "# Features and target\n",
        "features = [\n",
        "    'HomeTeam', 'AwayTeam', 'HTHG', 'HTAG', 'BWD', 'BWA', 'BWH',\n",
        "    'Year', 'Month', 'Day', \n",
        "    'Home_PrevWin', 'Home_PrevDraw', 'Home_PrevLoss', \n",
        "    'Away_PrevWin', 'Away_PrevDraw', 'Away_PrevLoss'\n",
        "]\n",
        "target = 'FTR_encoded'\n",
        "\n",
        "X = df[features]\n",
        "y = df[target]\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features (important for LSTM and regression)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n"
      ],
      "outputs": [],
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8KY4Y5YgUoOn",
        "outputId": "0e9396d9-d832-44a0-de1d-a5adb09891b0",
        "gather": {
          "logged": 1745895198032
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### XGBoost Classifier"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Model\n",
        "xgb_model = xgb.XGBClassifier(objective='multi:softmax', num_class=3, eval_metric='mlogloss')\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred_xgb = xgb_model.predict(X_test)\n",
        "\n",
        "# Accuracy\n",
        "print('XGBoost Accuracy:', accuracy_score(y_test, y_pred_xgb))\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "XGBoost Accuracy: 0.6117739515610487\n"
        }
      ],
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1745895219951
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Logistic Regression"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Model\n",
        "lr_model = LogisticRegression(max_iter=1000, multi_class='multinomial')\n",
        "lr_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred_lr = lr_model.predict(X_test_scaled)\n",
        "\n",
        "# Accuracy\n",
        "print('Logistic Regression Accuracy:', accuracy_score(y_test, y_pred_lr))\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Logistic Regression Accuracy: 0.6127027220118597\n"
        }
      ],
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1745895238049
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LSTM (using TensorFlow/Keras)"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "\n",
        "# Reshape input for LSTM: (samples, time_steps, features)\n",
        "# Here time_steps=1 because we don't have sequential data\n",
        "X_train_lstm = X_train_scaled.reshape((X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))\n",
        "X_test_lstm = X_test_scaled.reshape((X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))\n",
        "\n",
        "# Model\n",
        "lstm_model = Sequential()\n",
        "lstm_model.add(LSTM(64, input_shape=(X_train_lstm.shape[1], X_train_lstm.shape[2])))\n",
        "lstm_model.add(Dense(32, activation='relu'))\n",
        "lstm_model.add(Dense(3, activation='softmax'))  # 3 classes (H, D, A)\n",
        "\n",
        "lstm_model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train\n",
        "lstm_model.fit(X_train_lstm, y_train, epochs=20, batch_size=32, validation_split=0.1)\n",
        "\n",
        "# Evaluate\n",
        "loss, accuracy = lstm_model.evaluate(X_test_lstm, y_test)\n",
        "print('LSTM Accuracy:', accuracy)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "2025-04-29 02:54:33.353686: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2025-04-29 02:54:33.353728: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-04-29 02:54:33.354913: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2025-04-29 02:54:33.360509: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2025-04-29 02:54:34.184811: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Epoch 1/20\n1575/1575 [==============================] - 4s 2ms/step - loss: 0.8410 - accuracy: 0.6038 - val_loss: 0.8359 - val_accuracy: 0.6064\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/20\n1575/1575 [==============================] - 2s 1ms/step - loss: 0.8252 - accuracy: 0.6118 - val_loss: 0.8362 - val_accuracy: 0.6056\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/20\n1575/1575 [==============================] - 2s 1ms/step - loss: 0.8218 - accuracy: 0.6146 - val_loss: 0.8352 - val_accuracy: 0.6058\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/20\n1575/1575 [==============================] - 2s 1ms/step - loss: 0.8198 - accuracy: 0.6150 - val_loss: 0.8349 - val_accuracy: 0.6074\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/20\n1575/1575 [==============================] - 2s 1ms/step - loss: 0.8186 - accuracy: 0.6163 - val_loss: 0.8333 - val_accuracy: 0.6105\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/20\n1575/1575 [==============================] - 2s 1ms/step - loss: 0.8174 - accuracy: 0.6165 - val_loss: 0.8306 - val_accuracy: 0.6106\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/20\n1575/1575 [==============================] - 2s 1ms/step - loss: 0.8164 - accuracy: 0.6174 - val_loss: 0.8338 - val_accuracy: 0.6081\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/20\n1575/1575 [==============================] - 2s 1ms/step - loss: 0.8155 - accuracy: 0.6173 - val_loss: 0.8333 - val_accuracy: 0.6065\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/20\n1575/1575 [==============================] - 2s 1ms/step - loss: 0.8146 - accuracy: 0.6193 - val_loss: 0.8343 - val_accuracy: 0.6083\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/20\n1575/1575 [==============================] - 2s 1ms/step - loss: 0.8137 - accuracy: 0.6184 - val_loss: 0.8367 - val_accuracy: 0.6076\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/20\n1575/1575 [==============================] - 2s 1ms/step - loss: 0.8132 - accuracy: 0.6183 - val_loss: 0.8353 - val_accuracy: 0.6058\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/20\n1575/1575 [==============================] - 2s 1ms/step - loss: 0.8120 - accuracy: 0.6204 - val_loss: 0.8372 - val_accuracy: 0.6064\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/20\n1575/1575 [==============================] - 2s 1ms/step - loss: 0.8113 - accuracy: 0.6214 - val_loss: 0.8371 - val_accuracy: 0.6015\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/20\n1575/1575 [==============================] - 2s 1ms/step - loss: 0.8108 - accuracy: 0.6209 - val_loss: 0.8337 - val_accuracy: 0.6078\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/20\n1575/1575 [==============================] - 2s 1ms/step - loss: 0.8098 - accuracy: 0.6230 - val_loss: 0.8375 - val_accuracy: 0.6031\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 16/20\n1575/1575 [==============================] - 2s 1ms/step - loss: 0.8090 - accuracy: 0.6233 - val_loss: 0.8356 - val_accuracy: 0.6094\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 17/20\n1575/1575 [==============================] - 2s 1ms/step - loss: 0.8084 - accuracy: 0.6227 - val_loss: 0.8350 - val_accuracy: 0.6096\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 18/20\n1575/1575 [==============================] - 2s 1ms/step - loss: 0.8070 - accuracy: 0.6247 - val_loss: 0.8373 - val_accuracy: 0.6065\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 19/20\n1575/1575 [==============================] - 2s 1ms/step - loss: 0.8063 - accuracy: 0.6256 - val_loss: 0.8382 - val_accuracy: 0.6062\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 20/20\n1575/1575 [==============================] - 2s 1ms/step - loss: 0.8051 - accuracy: 0.6266 - val_loss: 0.8413 - val_accuracy: 0.6046\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n438/438 [==============================] - 0s 786us/step - loss: 0.8219 - accuracy: 0.6141\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nLSTM Accuracy: 0.6140601634979248\n"
        }
      ],
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1745895317296
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparison Table"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Collect predictions\n",
        "y_pred_xgb = xgb_model.predict(X_test)\n",
        "y_pred_lr = lr_model.predict(X_test_scaled)\n",
        "y_pred_lstm = np.argmax(lstm_model.predict(X_test_lstm), axis=1)  # for LSTM (softmax output)\n",
        "\n",
        "# Function to calculate metrics\n",
        "def get_metrics(y_true, y_pred, model_name):\n",
        "    return {\n",
        "        'Model': model_name,\n",
        "        'Accuracy': accuracy_score(y_true, y_pred),\n",
        "        'Precision': precision_score(y_true, y_pred, average='weighted'),\n",
        "        'Recall': recall_score(y_true, y_pred, average='weighted'),\n",
        "        'F1 Score': f1_score(y_true, y_pred, average='weighted')\n",
        "    }\n",
        "\n",
        "# Create metrics for each model\n",
        "metrics = []\n",
        "\n",
        "metrics.append(get_metrics(y_test, y_pred_xgb, 'XGBoost'))\n",
        "metrics.append(get_metrics(y_test, y_pred_lr, 'Logistic Regression'))\n",
        "metrics.append(get_metrics(y_test, y_pred_lstm, 'LSTM'))\n",
        "\n",
        "# Create DataFrame\n",
        "metrics_df = pd.DataFrame(metrics)\n",
        "\n",
        "# Show table\n",
        "print(metrics_df)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "438/438 [==============================] - 1s 710us/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n                 Model  Accuracy  Precision    Recall  F1 Score\n0              XGBoost  0.611774   0.595643  0.611774  0.600874\n1  Logistic Regression  0.612703   0.585205  0.612703  0.588191\n2                 LSTM  0.614060   0.593419  0.614060  0.597910\n"
        }
      ],
      "execution_count": 17,
      "metadata": {
        "gather": {
          "logged": 1745895476706
        }
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.16",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}